
# Multimodal Search ML

---

# Milestone 3

## Overview

This milestone focuses on building the data pipeline for the MultimodalSearchML project. We automated the ingestion, validation, preprocessing, and preparation of the dataset using TFX, ensured proper data versioning with DVC, and managed features with Feast as our feature store.

---

## Data Ingestion

- **Library used**: TFX ExampleGen

- **Dataset used:** query_features_with_timestamp.csv

- **Task**: Ingest raw data into the pipeline for future steps (statistics, schema generation, validation, and transformation).

I created a TFX pipeline component for ingestion using CsvExampleGen. Then, I loaded the dataset from:

```bash
data/query/query_features_with_timestamp.csv
```

The dataset is already prepared with query_id, f0 to f767 features, and an event_timestamp column.

```python
from tfx.components import CsvExampleGen
from tfx.proto import example_gen_pb2

input_config = example_gen_pb2.Input(splits=[
    example_gen_pb2.Input.Split(name='train', pattern='query_features_with_timestamp.csv'),
])

example_gen = CsvExampleGen(input_base=data_path, input_config=input_config)
```

- The CsvExampleGen is used to automatically:

	- Ingest the CSV file

	- Convert it into TFRecords

	- Automatically split into train and eval sets

	- Store generated artifacts under artifacts/CsvExampleGen

Results:

- You can observe the ingested data under:

```bash
tfx_pipeline/artifacts/CsvExampleGen/examples/
```

and inside:

```mathematica
Split-train/
Split-eval/
```

Each containing generated data_tfrecord-* files.

---

## Data Validation 

To automatically generate statistics, infer a data schema, and detect anomalies in the ingested query dataset before applying transformations or training models.

I added three essential components:

1. StatisticsGen: Computes descriptive statistics on the ingested data.

2. SchemaGen: Automatically infers the schema from the statistics.

3. ExampleValidator: Detects data anomalies and schema drift.

```python
from tfx.components import StatisticsGen, SchemaGen, ExampleValidator

# Compute statistics
statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])

# Infer schema
schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'])

# Validate dataset against the inferred schema
example_validator = ExampleValidator(
    statistics=statistics_gen.outputs['statistics'],
    schema=schema_gen.outputs['schema']
)
```

Pipeline Flow:

- Statistics are automatically computed from the TFRecords generated by ExampleGen.

- SchemaGen infers a schema without any manual intervention.

- ExampleValidator checks if:

    - The data conforms to the inferred schema.

    - There are missing values, unusual distributions, or unexpected types.

Results:

- Statistics are stored under:

```bash
tfx_pipeline/artifacts/StatisticsGen/statistics/
```

- Schema is stored under:

```bash
tfx_pipeline/artifacts/SchemaGen/schema/
```

- This is the output of our schema: (schame.pbtxt)

```mathematica
feature {
  name: "event_timestamp"
  type: BYTES
  domain: "event_timestamp"
  presence {
    min_fraction: 1.0
    min_count: 1
  }
  shape {
    dim {
      size: 1
    }
  }
}
feature {
  name: "f0"
  type: FLOAT
  presence {
    min_fraction: 1.0
    min_count: 1
  }
  shape {
    dim {
      size: 1
    }
  }
}
feature {
  name: "f1"
  type: FLOAT
  presence {
    min_fraction: 1.0
    min_count: 1
  }
  shape {
    dim {
      size: 1
    }
  }
}
.....
.....
feature {
  name: "f767"
  type: FLOAT
  presence {
    min_fraction: 1.0
    min_count: 1
  }
  shape {
    dim {
      size: 1
    }
  }
}
feature {
  name: "query_id"
  type: INT
  presence {
    min_fraction: 1.0
    min_count: 1
  }
  shape {
    dim {
      size: 1
    }
  }
}
string_domain {
  name: "event_timestamp"
  value: "2025-03-27 07:01:04.332726+00:00"
}
```

- Anomalies report is stored under:

```bash
tfx_pipeline/artifacts/ExampleValidator/anomalies/
```

NB:

- This process is fully automated thanks to TensorFlow Data Validation (TFDV).
- The schema file (schema.pbtxt) will serve as input for the next Transform step.
- Any anomalies detected can be analyzed in TensorBoard or directly via the generated artifacts.


---

## Data Preprocessing and Feature Engineering

Prepare the dataset for model training by applying transformations, selecting useful features, and managing missing data using TensorFlow Transform (TFX Transform).

I built a dedicated preprocessing module responsible for:

- Selecting only useful columns (768 embedding features).

- Handling potential missing data.

- Preparing the data for modeling in a scalable and production-friendly way. 

Preprocessing Module (preprocessing.py):

```python
import tensorflow as tf
import tensorflow_transform as tft

def preprocessing_fn(inputs):
    # Keep only feature columns f0 to f767
    outputs = {}
    for i in range(768):
        col = f"f{i}"
        outputs[col] = inputs[col]

    # Keep the event timestamp as is
    outputs['event_timestamp'] = inputs['event_timestamp']

    return outputs
```

TFX Transform Component (in the pipeline):

```python
from tfx.components import Transform

transform = Transform(
    examples=example_gen.outputs['examples'],
    schema=schema_gen.outputs['schema'],
    module_file=module_file,  # preprocessing.py script
)
```

What this step achieves:

- Reduces the dataset to only the needed features (f0 - f767 + timestamp).
- Ensures data is formatted consistently.
- Scales and prepares data in a reproducible way for future serving.
- The transformed dataset is automatically split into:
	- Split-train/
	- Split-eval/

Output Directories:

- Transform Graph:

```bash
tfx_pipeline/artifacts/Transform/transform_graph/
```

- Transformed Dataset:

```bash
tfx_pipeline/artifacts/Transform/transformed_examples/
```

---

## Feature Store

In this step, I integrated Feast as a feature store to manage and serve features for the MultimodalSearchML project. The feature store plays a crucial role in centralizing, versioning, and serving feature data for both training and serving machine learning models.

Objectives:

- Organize, version, and serve query and product dataset features.
- Enable consistent feature access during both training and inference.
- Prepare for later integration with the future TFX pipeline model training phase.

Data Used:

- query_features_flat.csv
- product_features_flat.parquet

These datasets contain extracted features representing query embeddings and product embeddings computed using CLIP models.

I installed Feast in a dedicated environment:

```bash
pip install feast==0.40.1
```

Then, initialized the feature repository:

```bash
feast init feature_store/multimodal_features
```

I defined two main FeatureViews:

1. Query Feature View from query_features_flat.csv
2. Product Feature View from product_features_flat.parquet

Example from query_features_view.py:

```python
query_feature_view = FeatureView(
    name="query_features_view",
    entities=[query_entity],
    ttl=Duration(seconds=86400),
    schema=[Field(name=f"f{i}", dtype=Float32) for i in range(768)],
    source=query_source
)
```

Example from product_features_view.py:

```python
product_feature_view = FeatureView(
    name="product_features_view",
    entities=[product_entity],
    ttl=Duration(seconds=86400),
    schema=[Field(name=f"f{i}", dtype=Float32) for i in range(768)],
    source=product_source
)
```
 
#### Feature Store Registration

Once the FeatureViews were defined, we applied them:

```bash
feast apply
```

Feast registered:

- 2 Entities (query_id and product_id)
- 2 FeatureViews
- Features with embedding dimensions: (f0 to f767 for queries) and (f0 to f1535 for products)

Feature Materialization: 

I materialized features to be ready for offline and online serving:

```bash
feast materialize-incremental $(date -u +%Y-%m-%d)
```

Feast then generated:

- Offline feature data (for training pipelines)
- Online feature data (for future model serving)

Summary: 

- Both datasets were successfully managed in Feast.
- Redis was configured as an online store (development purpose).
- The setup ensures that during model training or serving, the exact same feature values are retrieved as during feature generation.


